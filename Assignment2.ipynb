{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d79a4998",
   "metadata": {},
   "source": [
    "# Task 2: Exploring the performance of the generative model under differential privacy\n",
    "\n",
    "<br>\n",
    "\n",
    "咳咳咳，欢迎来到第二项任务。我们简要的介绍一下这个任务的基本情况，相关情况相信伍老师已经对大家做了一个基本的说明，在这里我再不厌其烦地啰嗦几句。\n",
    "\n",
    "<br>\n",
    "\n",
    "首先，本项任务是一个开放性的作业，在这项作业中，大家会学习到什么是差分隐私，并对差分隐私框架下的生成模型的进展有一些直观的了解。\n",
    "之后我们希望大家能发挥自己地聪明才智去探索一些不一样的策略，来确保模型满足差分隐私，并达到更好的效果（开放性地挑战）。\n",
    "\n",
    "<br>\n",
    "\n",
    "因此，大家的任务可以基本分成两个部分：\n",
    "\n",
    "- 基本任务：学习并完成我们这个notebook中的内容\n",
    "- 开放式的挑战：我们希望大家能够尽自己的可能去挑战“差分隐私下的生成模型”这个课题，也就是说，我们希望大家能够尽可能地去探索差分隐私框架下生成模型的极限是什么。\n",
    "\n",
    "<br>\n",
    "\n",
    "本项任务的由以下几个部分组成：\n",
    "\n",
    "- 首先是对生成模型和差分隐私的一个简要介绍\n",
    "- 我们介绍了当下如何保证深度学习模型的差分隐私的几类重要的方法\n",
    "- 我们给出了一些方法的代码，希望大家在调试的过程中能够加深对这些知识的理解\n",
    "- 开放式的作业环节\n",
    "\n",
    "<br>\n",
    "\n",
    "Overall, during this notebook, You will:\n",
    "\n",
    "- get familiar with the **Differential Privacy**\n",
    "- understanding how modern Generative model behave under differential privacy\n",
    "- learn how to use the library '**opacus**' to add differential privacy to the deep neural network\n",
    "\n",
    "Now, let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ae3631",
   "metadata": {},
   "source": [
    "# Generative models \n",
    "\n",
    "<br>\n",
    "\n",
    "这个部分我们并不会细讲，相信大家在伍老师课上也有了足够的了解，如果希望有一个更深地了解，或许 [NIPS 2016 Tutorial.pdf](./references/NIPS_2016_Tutorial.pdf) 是一个不错地学习材料。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de67c7",
   "metadata": {},
   "source": [
    "# What is differential privacy? \n",
    "\n",
    "<br>\n",
    "\n",
    "近些年来，先进的机器学习技术，特别是深度神经网络(Deep Neural Networks: DNN)，已经在图像处理，语音处理，医疗诊断，图像生成等领域取得了巨大的成功并引起了广泛地关注。深度学习的成功在很大程度上取决于用于训练机器学习模型的大量数据的收集，比如 ImageNet。然而，这些数据集合通常包含着许多敏感信息，在理想的情况下，我们希望我们的深度学习算法能够保证这些数据的隐私，换句话说，要能够保证输出模型从任何个人用户的细节中泛化出来。不幸的是，当下成熟的机器学习算法并没有做出这样的保证，事实上，尽管最先进的深度学习算法可以很好地泛化到测试集，但它们往往在实际训练过程中表现出过拟合这一现象，这表明模型对某些特定的训练数据是存在隐式的记忆的，这就导致了隐私泄露的问题。\n",
    "\n",
    "<br>\n",
    "\n",
    "与此同时，研究者们已经提出了几种侵犯隐私的攻击方式，以表明我们可以从不同的机器学习系统中提取敏感的私人信息， 因而，如何在保护此类隐私信息的同时允许数据集具有较高的学习效用自然受到了广泛的关注，差分隐私 (Differential Privacy, 以下简称为DP)正是保护在敏感数据上训练的 ML 模型隐私的常用技术。\n",
    "\n",
    "<br>\n",
    "\n",
    "差分隐私这一概念最早于2006年由美国哈佛大学的Cynthia Dwork等学者提出，这些年一直在稳健发展。通俗来讲，差分隐私就是针对给定的数据集合，在保留统计学特征的前提下去除个体特征以保护用户隐私。与之前隐私保护方法最大的不同之处在于，差分隐私引入了一种全新的数据保护模式来控制数据的搜集、查询及使用过程。这样的方法使得数据安全性、隐私性在得到理论保证的前提下，最大限度地支持了基于数据驱动的科学研究及商业活动，最大化地保留了已有数据的可用价值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaaf07f",
   "metadata": {},
   "source": [
    "# Deep learning with differential privacy\n",
    "\n",
    "<br>\n",
    "\n",
    "目前流行的差分私有机器学习方法是基于梯度扰动地形式（DP-SGD），在这种方式中我们执了一种加噪声地梯度下降形式，和传统的梯度下降算法不同，为了确保差分隐私，我们需要对反向传播过程中地梯度添加噪声, 具体细节请参照这份学习这份笔记 [Notes](./references/DP_notes.pdf)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4432caf",
   "metadata": {},
   "source": [
    "# environment for the experiment\n",
    "\n",
    "由于pytorch比较简单, 我们接下来的实验都基于pytorch来写。\n",
    "\n",
    "推荐大家使用conda来建立一个虚拟环境, 请大家务必先在虚拟环境里面先安装好pytorch等包, 然后从这个虚拟环境里重新启动notebook。\n",
    "\n",
    "如果不想麻烦，或许直接复制我的这个虚拟环境也是可以的，如下，我们需要先执行下面这个语句来安装\n",
    "\n",
    "当然你也可以自己配置虚拟环境，毕竟本实验不需要安装太多的库，大概就是**pytorch** 以及我们的需要用的DP库[opacus](https://opacus.ai/).(以上列出来的库可能不太全面，但我想应该问题不大了~）\n",
    "\n",
    "\n",
    "如果你复制我的虚拟环境遇到了困难，或许可以直接手动安装这些库，速度可能会更快，毕竟我的环境的里面还有一些其他的库。\n",
    "\n",
    "anyway, 这些都是细琐的环境问题~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51798443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step, make sure you have installed the required lib，Note it is Optional !!!\n",
    "# ! pip install -r requirement.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e294a672",
   "metadata": {},
   "source": [
    "## How to use libary 'opacus'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is just a demo code\n",
    "# 定义网络模型\n",
    "model = Net()\n",
    "# 定义优化器\n",
    "optimizer = SGD(model.parameters(), lr=0.05)\n",
    "privacy_engine = PrivacyEngine(\n",
    "    model,\n",
    "    sample_rate = 0.01,\n",
    "    alphas = [1,10,100],\n",
    "    noise_multiplier = 1.3,\n",
    "    max_grad_norm = 1.0,\n",
    ")\n",
    "#将定义的 privacy engine 添加到优化器上\n",
    "privacy_engine.attach(optimizer)\n",
    "## 好了，这样就大功告成了，非常简单是不是~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f64098",
   "metadata": {},
   "source": [
    "# Something must note here!!!\n",
    "\n",
    "<br>\n",
    "\n",
    "在上面的示例代码中我们给出了如何使用 facebook 开发的库 “opacus” 来对寻常的深度学习模型的训练添加差分隐私。示例看起来非常简单，但是有几个值得注意的地方，首先是这个 Privacy_engine 中的设置，你可能会好奇这个sample_rate , noise_multiplier, max_grad_norm 等都是真没意思， 如果你真的一点都不理解的话，还是建议你从头看一遍这份笔记[Notes](./references/DP_notes.pdf). 之后你可能会从这份 [F&Q](https://opacus.ai/docs/faq) 中获取补充内容，如果一切顺利的话，你应该可以大致了解这个类中的参数的具体含义了~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a611760",
   "metadata": {},
   "source": [
    "## How to build a generative model under differential privacy?\n",
    "\n",
    "在接下来的实验中请先确保你已经成功安装了pytorch和opacus！我们现在开始冲头搭建一个DP框架下的生成模型~~~\n",
    "\n",
    "<br>\n",
    "\n",
    "考虑到最简单的生成模型-DCGAN, 其生成器结构如下：\n",
    "\n",
    "<br>\n",
    "\n",
    "![avatar](./images/dcgan_generator.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "接下来，我们使用DP-SGD来训练这个一个DCGAN，看看是什么结果~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Runs DCGAN training with differential privacy.\n",
    "\n",
    "简单来说，因为我们使用DP-SGD的话会对梯度加噪声，很自然的，我们可以预期我们的生成结果不会很好。\n",
    "一般来说，小的模型会在DP框架下取得更好的效果（这里潜在的逻辑是： 越小的模型我们在反向转播是对梯度添加的噪声也越小，故而对模型性能的影响ye'bu's）。\n",
    "\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.utils.module_modification import convert_batchnorm_modules\n",
    "from opacus.utils.uniform_sampler import UniformWithReplacementSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--data-root\", default=\"./data\", help=\"path to dataset\")\n",
    "parser.add_argument(\n",
    "    \"--workers\", type=int, help=\"number of data loading workers\", default=2\n",
    ")\n",
    "parser.add_argument(\"--batch-size\", type=int, default=64, help=\"input batch size\")\n",
    "parser.add_argument(\n",
    "    \"--sample-rate\",\n",
    "    type=float,\n",
    "    default=0.018,\n",
    "    help=\"sample rate used for batch construction\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--imageSize\",\n",
    "    type=int,\n",
    "    default=32,\n",
    "    help=\"the height / width of the input image to network\",\n",
    ")\n",
    "parser.add_argument(\"--nz\", type=int, default=100, help=\"size of the latent z vector\")\n",
    "parser.add_argument(\"--ngf\", type=int, default=128)\n",
    "parser.add_argument(\"--ndf\", type=int, default=128)\n",
    "parser.add_argument(\n",
    "    \"--epochs\", type=int, default=25, help=\"number of epochs to train for\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--lr\", type=float, default=0.0002, help=\"learning rate, default=0.0002\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--beta1\", type=float, default=0.5, help=\"beta1 for adam. default=0.5\"\n",
    ")\n",
    "parser.add_argument(\"--ngpu\", type=int, default=1, help=\"number of GPUs to use\")\n",
    "parser.add_argument(\"--netG\", default=\"\", help=\"path to netG (to continue training)\")\n",
    "parser.add_argument(\"--netD\", default=\"\", help=\"path to netD (to continue training)\")\n",
    "parser.add_argument(\n",
    "    \"--outf\", default=\"./result\", help=\"folder to output images and model checkpoints\"\n",
    ")\n",
    "parser.add_argument(\"--manualSeed\", type=int, help=\"manual seed\")\n",
    "parser.add_argument(\n",
    "    \"--target-digit\",\n",
    "    type=int,\n",
    "    default=8,\n",
    "    help=\"the target digit(0~9) for MNIST training\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--device\",\n",
    "    type=str,\n",
    "    default=\"cuda\",\n",
    "    help=\"GPU ID for this process (default: 'cuda')\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--disable-dp\",\n",
    "    action=\"store_true\",\n",
    "    default=False,\n",
    "    help=\"Disable privacy training and just train with vanilla SGD\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--secure-rng\",\n",
    "    action=\"store_true\",\n",
    "    default=False,\n",
    "    help=\"Enable Secure RNG to have trustworthy privacy guarantees. Comes at a performance cost\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-r\",\n",
    "    \"--n-runs\",\n",
    "    type=int,\n",
    "    default=1,\n",
    "    metavar=\"R\",\n",
    "    help=\"number of runs to average on (default: 1)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--sigma\",\n",
    "    type=float,\n",
    "    default=1.0,\n",
    "    metavar=\"S\",\n",
    "    help=\"Noise multiplier (default 1.0)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-c\",\n",
    "    \"--max-per-sample-grad_norm\",\n",
    "    type=float,\n",
    "    default=1.0,\n",
    "    metavar=\"C\",\n",
    "    help=\"Clip per-sample gradients to this norm (default 1.0)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--delta\",\n",
    "    type=float,\n",
    "    default=1e-5,\n",
    "    metavar=\"D\",\n",
    "    help=\"Target delta (default: 1e-5)\",\n",
    ")\n",
    "\n",
    "opt = parser.parse_args()\n",
    "\n",
    "try:\n",
    "    os.makedirs(opt.outf)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "if opt.manualSeed is None:\n",
    "    opt.manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", opt.manualSeed)\n",
    "random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if opt.data_root is None:\n",
    "    raise ValueError(\"`data-root` parameter is required.\")\n",
    "\n",
    "try:\n",
    "    dataset = dset.MNIST(\n",
    "        root=opt.data_root,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(opt.imageSize),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    idx = dataset.targets == opt.target_digit\n",
    "    dataset.targets = dataset.targets[idx]\n",
    "    dataset.data = dataset.data[idx]\n",
    "    nc = 1\n",
    "except ValueError:\n",
    "    print(\"Cannot load dataset\")\n",
    "\n",
    "if opt.secure_rng:\n",
    "    try:\n",
    "        import torchcsprng as prng\n",
    "    except ImportError as e:\n",
    "        msg = (\n",
    "            \"To use secure RNG, you must install the torchcsprng package! \"\n",
    "            \"Check out the instructions here: https://github.com/pytorch/csprng#installation\"\n",
    "        )\n",
    "        raise ImportError(msg) from e\n",
    "\n",
    "    generator = prng.create_random_device_generator(\"/dev/urandom\")\n",
    "\n",
    "else:\n",
    "    generator = None\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    generator=generator,\n",
    "    batch_sampler=UniformWithReplacementSampler(\n",
    "        num_samples=len(dataset),\n",
    "        sample_rate=opt.sample_rate,\n",
    "        generator=generator,\n",
    "    ),\n",
    ")\n",
    "\n",
    "device = torch.device(opt.device)\n",
    "ngpu = int(opt.ngpu)\n",
    "nz = int(opt.nz)\n",
    "ngf = int(opt.ngf)\n",
    "ndf = int(opt.ndf)\n",
    "\n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(nz, ngf * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 32 x 32\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output\n",
    "\n",
    "\n",
    "netG = Generator(ngpu)\n",
    "if not opt.disable_dp:\n",
    "    netG = convert_batchnorm_modules(netG)\n",
    "netG = netG.to(device)\n",
    "netG.apply(weights_init)\n",
    "if opt.netG != \"\":\n",
    "    netG.load_state_dict(torch.load(opt.netG))\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 32 x 32\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 16 x 16\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 8 x 8\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 4 x 4\n",
    "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "\n",
    "        return output.view(-1, 1).squeeze(1)\n",
    "\n",
    "\n",
    "netD = Discriminator(ngpu)\n",
    "if not opt.disable_dp:\n",
    "    netD = convert_batchnorm_modules(netD)\n",
    "    netG = convert_batchnorm_modules(netG)\n",
    "netD = netD.to(device)\n",
    "netD.apply(weights_init)\n",
    "if opt.netD != \"\":\n",
    "    netD.load_state_dict(torch.load(opt.netD))\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "FIXED_NOISE = torch.randn(opt.batch_size, nz, 1, 1, device=device)\n",
    "REAL_LABEL = 1.0\n",
    "FAKE_LABEL = 0.0\n",
    "\n",
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "\n",
    "privacy_engine = PrivacyEngine(\n",
    "    netD,\n",
    "    sample_rate=opt.sample_rate,\n",
    "    alphas=[1 + x / 10.0 for x in range(1, 100)] + list(range(12, 64)),\n",
    "    noise_multiplier=opt.sigma,\n",
    "    max_grad_norm=opt.max_per_sample_grad_norm,\n",
    "    secure_rng=opt.secure_rng,\n",
    ")\n",
    "if not opt.disable_dp:\n",
    "    privacy_engine.attach(optimizerD)\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "\n",
    "for epoch in range(opt.epochs):\n",
    "    data_bar = tqdm(dataloader)\n",
    "    for i, data in enumerate(data_bar, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "\n",
    "        optimizerD.zero_grad()\n",
    "\n",
    "        real_data = data[0].to(device)\n",
    "        batch_size = real_data.size(0)\n",
    "\n",
    "        # train with fake\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        label_fake = torch.full((batch_size,), FAKE_LABEL, device=device)\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, label_fake)\n",
    "        errD_fake.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # train with real\n",
    "        label_true = torch.full((batch_size,), REAL_LABEL, device=device)\n",
    "        output = netD(real_data)\n",
    "        errD_real = criterion(output, label_true)\n",
    "        errD_real.backward()\n",
    "        optimizerD.step()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        optimizerG.zero_grad()\n",
    "        label_g = torch.full((batch_size,), REAL_LABEL, device=device)\n",
    "        output_g = netD(fake)\n",
    "        errG = criterion(output_g, label_g)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "        data_bar.set_description(\n",
    "            f\"epoch: {epoch}, Loss_D: {errD.item()} \"\n",
    "            f\"Loss_G: {errG.item()} D(x): {D_x} \"\n",
    "            f\"D(G(z)): {D_G_z1}/{D_G_z2}\"\n",
    "        )\n",
    "\n",
    "        if not opt.disable_dp:\n",
    "            epsilon, best_alpha = optimizerD.privacy_engine.get_privacy_spent(opt.delta)\n",
    "            print(\n",
    "                \"(ε = %.2f, δ = %.2f) for α = %.2f\" % (epsilon, opt.delta, best_alpha)\n",
    "            )\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            vutils.save_image(\n",
    "                real_data, \"%s/real_samples.png\" % opt.outf, normalize=True\n",
    "            )\n",
    "            fake = netG(FIXED_NOISE)\n",
    "            vutils.save_image(\n",
    "                fake.detach(),\n",
    "                \"%s/fake_samples_epoch_%03d.png\" % (opt.outf, epoch),\n",
    "                normalize=True,\n",
    "            )\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(netG.state_dict(), \"%s/netG_epoch_%d.pth\" % (opt.outf, epoch))\n",
    "    torch.save(netD.state_dict(), \"%s/netD_epoch_%d.pth\" % (opt.outf, epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f5878e",
   "metadata": {},
   "source": [
    "# How about your result?\n",
    "\n",
    "Note: 本实验可能需要一个至少（4G）的GPU才跑得起来，如果你遇到了GPU显存不够的问题，可以尝试如下一个解决思路\n",
    "- 调小 batch-size\n",
    "- 调小模型的大小（具体来说就是ndf和ngf）\n",
    "- 用cpu跑（如果你没有显卡的话~）\n",
    "\n",
    "<br>\n",
    "\n",
    "在这里，我给出的我的实验结果\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"./images/real_samples.png\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">真实的图片</div>\n",
    "</center>\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"./images/fake_samples_epoch_024.png\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">生成的图片</div>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "显然，我们可以发现对梯度加噪声这一步对模型的结果有很大的影响，具体来说\n",
    "- 从生成的结果来看，图片非常的模糊\n",
    "- 从多样性来看，模型陷入了 model collapse, 生成的图片的非常单一.\n",
    "\n",
    "自然的，我们可以考虑一个对一个更强的GAN来加DP，并希望这种方式能够取得更好的效果，或者其他方式，例如：\n",
    "\n",
    "<br>\n",
    "\n",
    "- 比如,考虑[wasserstein GAN](https://arxiv.org/abs/1704.00028)，这是GAN的一个突破，他解决了模型不易训练的问题，自然的，有人就已经做了这个工作[DP+WGAN](https://arxiv.org/pdf/1802.06739.pdf)\n",
    "\n",
    "<br>\n",
    "\n",
    "- 或者引入先验知识的CGAN, [DP+CGAN](https://arxiv.org/abs/2001.09700)\n",
    "\n",
    "<br>\n",
    "\n",
    "- 又或者，我们不考虑使用DP-SGD， 我们针对GAN的这种特定结构，对训练过程中的一部分加噪声，这就有了2020年CVPR地一篇文章[GS-WAGN](https://arxiv.org/pdf/2006.08265.pdf)\n",
    "\n",
    "<br>\n",
    "\n",
    "- 又或者，不管是DP-SGD还是GS-WGAN，他们都是基于训练过程的DP方式（对训练过程中的梯度加扰动），那么既然GAN在训练过程中其实是不断地衡量真实数据和生成数据之间的部分，那么，对于目标函数做扰动是不是可行的？这也就有了今年ICML地一篇 oral [DP-SWD](https://arxiv.org/pdf/2107.01848.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d15f02",
   "metadata": {},
   "source": [
    "#  GS-WGAN: A Gradient-Sanitized Approach for Learning Differentially Private Generators (NeurIPS 2020).\n",
    "\n",
    "<br>\n",
    "\n",
    "在之前的实验中，我们看到直接使用DP-SGD来训练DCGAN效果可以说是非常差的，这自然就使得研究人员去探究怎么去给生成模型加DP(或者说噪声)能够既保持一定的模型实用性，又能有比较好的DP保证。现在我们简单的讲一讲2020年NeurIPS的一篇文章[GS-WAGN](https://arxiv.org/pdf/2006.08265.pdf)。\n",
    "\n",
    "<br>\n",
    "\n",
    "首先，我们先来分析一下 DP-SGD 在干什么\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"./images/dp_sgd.png\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">DP_SGD</div>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "首先是正常的反向传播，得到各个网络层参数的梯度，然后为了确保差分隐私，我们需要为梯度添加噪声，这由两步组成\n",
    "- 梯度裁剪 $ clip(g^{(t)},C) $ ，这个C是一个人为给定的超参数，意思是我们的梯度最大不能超过这个阈值，这一步的目的是为了控制敏感度，可以这样直观理解，如果有某个部分的梯度特别重要，那我们会认为这一部分就容易受到攻击。\n",
    "\n",
    "- 添加噪声 $ +N(0, \\delta^2C^2I) $, 这一步就是正常的加噪步骤了。\n",
    "- 最后由被扰动的梯度代替原来的梯度进行反向传播。\n",
    "\n",
    "好，那DP_SGD的问题是什么呢？\n",
    "\n",
    "- 梯度裁剪这一步损失了太多的信息，自然导致了实用性的下降\n",
    "- 在实际的过程中，寻求一个合理的C（技能保证模型的性能，又能确保隐私）其实也并不容易。\n",
    "\n",
    "那怎么解决这个缺点呢， 作者通过针对GAN的结构选择性的添加噪声并结合 Wasserstein GAN 的想法对梯度加一个正则来控制这个敏感度。\n",
    "\n",
    "<br>\n",
    "\n",
    "首先是选择性的添加噪声机制\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"./images/GS_WGAN.png\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">GS-WGAN</div>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "上图显示了GS-WGAN的示意图，左图是正常的GAN的流程，右图是GS-WGAN的流程。\n",
    "\n",
    "<br>\n",
    "\n",
    "我们可以看到，正常的GAN的流程是什么？ 我们从高斯白噪声出发，经过生成器生成一个一张（或者一个batch）的假样本，然后我们将生成的样本和真实样本（也就是我们需要保护的数据）送入判别器，然后得到相应的loss, 然后梯度回传，更新判别器和生成器。\n",
    "\n",
    "<br>\n",
    "\n",
    "注意到，在上面我们使用DP-SGD训练DCGAN的时候，我们实际上是对判别器的梯度加了噪声，然后根据后处理机制，只要 $ \\Delta D(x) $ 是DP的，那么我生成器的梯度 $ g_G $ 也自然是DP的，这种方式实际上是对整个GAN都加了噪声。\n",
    "\n",
    "<br>\n",
    "\n",
    "然而，由于DP框架下生成模型的只需要我们 release 这个生成器 (generator)， 也就是说实际上我们并不需要对这整个模型加噪声，我们只要将这个DP机制加在生成器上，也就是说，我们的判别器还是正常的训练，只不过扰动的梯度代替生成器的梯度来训练我们的generator,如下：\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"./images/GS_WGAN_2.png\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">选择性的添加噪声</div>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "至于在损失函数中添加一个正则项来控制梯度不会太大（或者说控制敏感度）这一技巧也在论文中的[第4章节](https://arxiv.org/pdf/2006.08265.pdf), 这里我们就不展开讲了，有兴趣的同学可以自行阅读。\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"./images/GS_WGAN3.png\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">GS-WGAN的结果</div>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "我们可以看到，这个结果还是比较好的（至少在MINIST数据集上），这篇文章的代码可以在[这里](https://github.com/DingfanChen/GS-WGAN)找到，考虑到同学们可能并没有一个至少22G的显卡，这个模型可能大家跑不起来，因此，在这里，有条件的同学可以试一试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cc1265",
   "metadata": {},
   "source": [
    "# What should you do？\n",
    "\n",
    "到这里，我们的主体内容已经基本结束了，我们总结一下，到目前为止，我们基本为大家讲述了差分隐私目前在生成模型领域的一个进展\n",
    "- 从最自然的想法——就是使用一个保证差分隐私的算法去训练一个生成模型（我们展示了如何使用DP-SGD算法去训练DCGAN模型的例子）\n",
    "- 到发现直接用 DP_SGD 算法去做不太好之后，研究人员选择了一些改进策略，比如选择性的添加噪声(这就有了GS-WGAN)，又或者基于梯度扰动的算法可能不是很好，那我就直接做一个DP的目标函数(这就是[DP-SWD](https://arxiv.org/pdf/2107.01848.pdf)得想法）, 等等，这里不一一列举。\n",
    "\n",
    "<br>\n",
    "\n",
    "在上面我们简要介绍了GS-WGAN的核心想法，目的是希望大家能通过这个例子来理解当下的研究者是如何对这个问题进行改进的。这也是我们希望大家去探索的，具体来说，我们希望大家能够做这些事情: \n",
    "\n",
    "- 给出一个你天马行空的想法，可以参照下面的一些思路。\n",
    "- 如果可以的话，尽量给出你的实验结果。\n",
    "- 一份报告（或者说就是一个小论文），他并不一定要多么地严谨，但是核心内容应当是：你的想法是什么，依据是什么？\n",
    "\n",
    "实际上，我们并不指望大家一定要将这个作业的有多么的完备，换句话说，（可以没有证明，没有完备的实验，也没有太多仔细的分析，当然有是最好），那我们希望大家做什么？ 就是尽可能地给一个你的思路，然后用一些基本的实验或者理论来做支撑，如果条件允许的话，尽可能地给出你的实验，越详细越好。我们将根据大家的报告内容来给大家的这次作业打分，祝大家旅途愉快~\n",
    "\n",
    "<br>\n",
    "\n",
    "**一些可能的思路**：\n",
    "- **探索不同的生成模型？** 我们前面看到使用DP_SGD算法去训练DCGAN的效果是非常差的，那么有的人就想到了[WassesteinGAN](https://arxiv.org/pdf/1802.06739.pdf), 当然，既然是生成模型，我们自然可以不局限于GAN, [DP+VAE](https://arxiv.org/abs/1812.02274)方式也是可行的.\n",
    "- **不同的训练方式？** 比如教师-学生网路模型[PATE-GAN](https://openreview.net/forum?id=S1zk9iRqF7)，[Data-Lens](https://arxiv.org/pdf/2103.11109.pdf)\n",
    "- **又或者对现有的DP-SGD算法做改进？** 既然差分隐私在大模型上有维数灾难（用人话讲就是，大模型参数更多，自然的我要加的噪声也更多，那如果考虑梯度扰动的方法，我能不能把梯度先往低维空间投影，然后在加噪声，最后用这个低维的梯度在更新网络参数？），这方面地工作可以参考[网络的参数矩阵分解](https://arxiv.org/pdf/2106.09352.pdf), 又或者[梯度的低维空间投影](https://openreview.net/forum?id=7dpmlkBuJFC).\n",
    "- more...\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a816c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl)",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
