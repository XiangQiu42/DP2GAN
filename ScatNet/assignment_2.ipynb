{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the scattering transforms to build a Classification Model（散射网络进阶）\n",
    "\n",
    "在上个实验中（assignment_1），我们学习了什么是小波散射变换，并对其有了一个初步的认识（hope so...）, 但是在实际的使用中肯定不是用上个实验中那么简单的模型了，总之，在这里我们使用散射网络来搭建一个分类模型（基于Fashion-MNIST数据集，至于为啥不用大一点的，可以参考下面的注释QAQ）。\n",
    "\n",
    "This notebook is about classification. You will:\n",
    "\n",
    "- using the scattering transforms to bulid a **deep convolution Net**\n",
    "- use the model above to do classification on Fashion-MNIST\n",
    "\n",
    "\n",
    "*Note here, given that U may not be able to use a GPU to accelerate the train process , here our example is based on the Fashion-MNIST datasets, hope that it will works well for U, good luck!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面这行命令可能不是必须的！！!\n",
    "# 如果你的 Notebook 老是挂掉然后重启的话可能这行命令是有用的~\n",
    "import os \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先，平平无奇的加载一些库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torchvision import datasets, transforms\n",
    "from kymatio.torch import Scattering2D\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 测试能否使用 GPU 加速\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 然后，获取数据集\n",
    "train_set = datasets.FashionMNIST(root='.data', train=True,\n",
    "                                  transform=transforms.ToTensor(),\n",
    "                                  download=True)\n",
    "test_set = datasets.FashionMNIST(root='.data', train=False,\n",
    "                                 transform=transforms.ToTensor(),\n",
    "                               download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need you to implement the follow function !!!\n",
    "\n",
    "回顾一下，假设我们输入是一张二维的灰度图像，它的大小是（B,C,H,W）,B代表batch-size,C代表通道数（RGB图像为3，灰度图像为1），HxW代表图像的分辨率了，那么散射网络的输出大小应当是 \n",
    "\n",
    "$$ (B,C,\\frac{1+LJ+L^{2}J(J-1)}{2},\\frac{H}{2^J},\\frac{W}{2^J} )$$\n",
    "\n",
    "请根据该关系完成下面的函数！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scatter_transform(device):\n",
    "    shape = (28, 28, 1)\n",
    "    scattering = Scattering2D(J=2, shape=shape[:2]).to(device)\n",
    "    K = None\n",
    "    (h, w) = shape[:2]\n",
    "    ##############################################################################\n",
    "    # TODO: This function is to get the scattring transform obeject and return   #\n",
    "    #        the channels(represented by 'K') after scatting transform, please   #\n",
    "    #        implemrnt this fucntion according to the relationship above.        #\n",
    "    # Note the type of h and w is int                                            #\n",
    "    ##############################################################################\n",
    "    \n",
    "    ##############################################################################\n",
    "    #                             END OF YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "    return scattering, K, (h, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulid our mode\n",
    "\n",
    "接下来我们需要创建一个类我们建立一个简单的分类模型（只有两个卷积层，不过对于FMNIST这种大小的数据集也够了~）\n",
    "\n",
    "这个模型的结构如下：\n",
    "\n",
    "```python\n",
    "Scattering2dCNN(\n",
    "  (bn): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (features): Sequential(\n",
    "    (0): Conv2d(81, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (3): ReLU(inplace=True)\n",
    "  )\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=1024, out_features=32, bias=True)\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): Linear(in_features=32, out_features=10, bias=True)\n",
    "  )\n",
    ")\n",
    "```\n",
    "\n",
    "注意到在如上的模型种我们并没有将散射变换集成到我们的模型之中（这当然也是可以的~），但是由于散射网络并不需要学习，所以这两种方式其实区别不大\n",
    "\n",
    "anyway, 这里需要你把上面这个模型实现出来QAQ!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scattering2dCNN(nn.Module):\n",
    "    '''\n",
    "        Simple CNN model with features extrated bu ScatNet\n",
    "    '''\n",
    "    def __init__(self, in_channels):\n",
    "        super(Scattering2dCNN, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        self.bn = None\n",
    "        self.features = None\n",
    "        self.classifier = None\n",
    "        \n",
    "        self.build()\n",
    "\n",
    "    def build(self):\n",
    "        ##############################################################################\n",
    "        # TODO:  implement the build function to realize a model showed above        #\n",
    "        ##############################################################################\n",
    "        \n",
    "        ##############################################################################\n",
    "        #                             END OF YOUR CODE                               #\n",
    "        ##############################################################################\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(x.view(-1, self.in_channels, 7, 7))\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's your job to finish the train process\n",
    "\n",
    "请将训练过程补充完整，如果实在不会的话，可以参考下面的 test 函数~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function of train process\n",
    "def train(model, device, train_loader, optimizer, epoch, scattering):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    num_examples = 0\n",
    "    correct = 0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        output = None\n",
    "        loss = None\n",
    "        ##############################################################################\n",
    "        # TODO:  implement the train process                                        #\n",
    "        # Note the the overall process is:                                          #\n",
    "        #             input-> scattering transform -> CNN -> output                 #\n",
    "        # Hint: the loss function could be Cross entropy loss function              #\n",
    "        ##############################################################################\n",
    "        \n",
    "        ##############################################################################\n",
    "        #                             END OF YOUR CODE                               #\n",
    "        ##############################################################################\n",
    "        \n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        train_loss += F.cross_entropy(output, target).item()\n",
    "        num_examples += len(data)\n",
    "            \n",
    "    train_loss /= batch_idx\n",
    "    train_acc = 100. * correct / num_examples\n",
    "    \n",
    "    print(f'Train set: Average loss: {train_loss:.4f}, '\n",
    "            f'Accuracy: {correct}/{num_examples} ({train_acc:.2f}%)')\n",
    "    \n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function of test process\n",
    "def test(model, device, test_loader, scattering):\n",
    "    model.eval()\n",
    "    \n",
    "    num_batchs = 0\n",
    "    num_examples = 0\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(scattering(data))\n",
    "            test_loss += F.cross_entropy(output, target).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            num_examples += len(data)\n",
    "            num_batchs += 1\n",
    "\n",
    "    test_loss /= num_batchs\n",
    "    test_acc = 100. * correct / num_examples\n",
    "\n",
    "    print(f'Test set: Average loss: {test_loss:.4f}, '\n",
    "          f'Accuracy: {correct}/{num_examples} ({test_acc:.2f}%)')\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 现在开始我们的主函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取我们的散射网络的对象\n",
    "scattering, K, _ = get_scatter_transform(device)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# DataLoaders\n",
    "if use_cuda:\n",
    "    num_workers = 4\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = None\n",
    "    pin_memory = False\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "# then load our model\n",
    "model = Scattering2dCNN(K).to(device)\n",
    "\n",
    "## 定义优化器\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "## 可以看看你建立的模型是啥个样子\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 所以咱们这就开始训练了~~\n",
    "\n",
    "考虑到大家可能在机房可能没有显卡，这个epoch就设置的比较小，当然这个也是小问题了, 大家可以根据实际情况自己修改~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "test_acc_history = []\n",
    "for epoch in range(0, 20):\n",
    "    print(f\"\\nEpoch: {epoch}\")\n",
    "    trian_loss, train_acc = train(model, device, train_loader, optimizer, epoch+1, scattering)\n",
    "    _, test_acc = test(model, device, test_loader, scattering)\n",
    "    train_loss_history.append(trian_loss)\n",
    "    train_acc_history.append(train_acc)\n",
    "    test_acc_history.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Run this cell to visualize training loss and train / val accuracy\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title(' Train loss')\n",
    "plt.plot(train_loss_history, '-*')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(train_acc_history, '-o', label='train')\n",
    "plt.plot(test_acc_history, '-o', label='test')\n",
    "plt.plot([0.5] * len(test_acc_history), 'k--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 到这里就结束了！！\n",
    "\n",
    "首先按照惯例给出我的训练结果做一个参考：\n",
    "\n",
    "![avatar](./images/assignment_2_1.png)\n",
    "\n",
    "如果你一步步的做的话，我想得到类似的结果应该问题不大，其实若是你细致一些的话，你会发现其实跑几个Epoch模型就已经过拟合了，但是这并不是这里的重点，总之，到这里你已经对散射网络有了一个基本的了解了,希望这能对你有所帮助，再会~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l_pytorch]",
   "language": "python",
   "name": "conda-env-d2l_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
