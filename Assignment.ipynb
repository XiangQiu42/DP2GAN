{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d79a4998",
   "metadata": {},
   "source": [
    "# Task: Exploring the performance of the generative model under differential privacy\n",
    "\n",
    "<br>\n",
    "\n",
    "咳咳咳，欢迎来到这个课程作业。我们简要的介绍一下这个任务的基本情况，相关情况相信伍老师已经对大家做了一个基本的说明，在这里我再不厌其烦地啰嗦几句。\n",
    "\n",
    "<br>\n",
    "\n",
    "首先，本项任务是一个开放性的作业，在这项作业中，大家会学习到什么是差分隐私，并对差分隐私框架下的生成模型的进展有一些直观的了解。\n",
    "之后我们希望大家能发挥自己地聪明才智去探索一些不一样的策略，来确保模型满足差分隐私，并达到更好的效果（开放性地挑战）。\n",
    "\n",
    "<br>\n",
    "\n",
    "因此，大家的任务可以基本分成两个部分：\n",
    "\n",
    "- 基本任务：学习并完成我们这个notebook中的内容\n",
    "- 开放式的挑战：我们希望大家能够尽自己的可能去挑战“差分隐私下的生成模型”这个课题，也就是说，我们希望大家能够尽可能地去探索差分隐私框架下生成模型的极限是什么。\n",
    "\n",
    "<br>\n",
    "\n",
    "本项任务的由以下几个部分组成：\n",
    "\n",
    "- 首先是对生成模型和差分隐私的一个简要介绍\n",
    "- 我们介绍了当下如何保证深度学习模型的差分隐私的几类重要的方法\n",
    "- 我们给出了一些方法的代码，希望大家在调试的过程中能够加深对这些知识的理解\n",
    "- 开放式的作业环节\n",
    "\n",
    "<br>\n",
    "\n",
    "Overall, during this notebook, You will:\n",
    "\n",
    "- get familiar with the **Differential Privacy**\n",
    "- understanding how modern Generative model behave under differential privacy\n",
    "- learn how to use the library '**opacus**' to add differential privacy to the deep neural network\n",
    "\n",
    "Now, let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ae3631",
   "metadata": {},
   "source": [
    "# Generative models \n",
    "\n",
    "<br>\n",
    "生成领域最常见的几类模型应该是变分自编码器，生成对抗网络，以及最近如火如荼的扩散模型~\n",
    "\n",
    "我们在这里主要看一下生成对抗网络，这个部分我们并不会细讲，相信大家对GAN已经有了足够的了解，如果希望有一个更深的了解，或许[NIPS 2016 Tutorial](./references/NIPS_2016_Tutorial.pdf) 是一个不错的学习材料。 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de67c7",
   "metadata": {},
   "source": [
    "# What is differential privacy? \n",
    "\n",
    "<br>\n",
    "\n",
    "近些年来，先进的机器学习技术，特别是深度神经网络(Deep Neural Networks, DNN)，已经在图像处理，语音处理，医疗诊断，图像生成等领域取得了巨大的成功并引起了广泛地关注。深度学习的成功在很大程度上取决于用于训练机器学习模型的大量数据的收集，比如 ImageNet。然而，这些数据集合通常包含着许多敏感信息，在理想的情况下，我们希望我们的深度学习算法能够保证这些数据的隐私，换句话说，要能够保证输出模型从任何个人用户的细节中泛化出来。不幸的是，当下成熟的机器学习算法并没有做出这样的保证，事实上，尽管最先进的深度学习算法可以很好地泛化到测试集，但它们往往在实际训练过程中表现出过拟合这一现象，这表明模型对某些特定的训练数据是存在隐式的记忆的，这就导致了隐私泄露的问题。\n",
    "\n",
    "<br>\n",
    "\n",
    "与此同时，研究者们已经提出了几种侵犯隐私的攻击方式，以表明我们可以从不同的机器学习系统中提取敏感的私人信息， 因而，如何在保护此类隐私信息的同时允许数据集具有较高的学习效用自然受到了广泛的关注，差分隐私 (Differential Privacy, 以下简称为DP)正是保护在敏感数据上训练的 ML 模型隐私的常用技术。\n",
    "\n",
    "<br>\n",
    "\n",
    "差分隐私这一概念最早于2006年由美国哈佛大学的Cynthia Dwork等学者提出，这些年一直在稳健发展。通俗来讲，差分隐私就是针对给定的数据集合，在保留统计学特征的前提下去除个体特征以保护用户隐私。与之前隐私保护方法最大的不同之处在于，差分隐私引入了一种全新的数据保护模式来控制数据的搜集、查询及使用过程。这样的方法使得数据安全性、隐私性在得到理论保证的前提下，最大限度地支持了基于数据驱动的科学研究及商业活动，最大化地保留了已有数据的可用价值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaaf07f",
   "metadata": {},
   "source": [
    "# Deep learning with differential privacy\n",
    "\n",
    "<br>\n",
    "目前主流的差分隐私深度生成模型基于如下两个框架：\n",
    "\n",
    "- 差分隐私的随机梯度下降算法(DPSGD)\n",
    "\n",
    "- 教师模型的私有聚合（PATE）\n",
    "\n",
    "我们在这个作业中我们专注于DPSGD算法的应用，DPSGD算法执行了一种带噪声的梯度下降形式，和传统的梯度下降算法不同，为了确保差分隐私，我们需要对反向传播过程中地梯度添加噪声（详见PPT，或者参照这份学习这份笔记 [Notes](./references/DP_notes.pdf)）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4432caf",
   "metadata": {},
   "source": [
    "# Environment for the experiment\n",
    "\n",
    "由于pytorch比较简单, 我们接下来的实验都基于pytorch来写。\n",
    "\n",
    "\n",
    "推荐大家使用conda来建立一个虚拟环境, 请大家务必先在虚拟环境里面先安装好pytorch等包, 然后从这个虚拟环境里重新启动notebook。\n",
    "\n",
    "\n",
    "本实验不需要安装太多的库，大概就是**pytorch** 以及我们的需要用的DP库[opacus](https://opacus.ai/).\n",
    "\n",
    "\n",
    "你可以通过conda或者pip的形式来安装，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51798443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step, make sure you have installed the required lib\n",
    "# !pip install opacus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e294a672",
   "metadata": {},
   "source": [
    "## How to use libary 'opacus'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is just a demo code\n",
    "\n",
    "# define your components as usual\n",
    "model = Net()\n",
    "optimizer = SGD(model.parameters(), lr=0.05)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=1024)\n",
    "\n",
    "# enter PrivacyEngine\n",
    "privacy_engine = PrivacyEngine()\n",
    "model, optimizer, data_loader = privacy_engine.make_private(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=data_loader,\n",
    "    noise_multiplier=1.1,\n",
    "    max_grad_norm=1.0,\n",
    ")\n",
    "# Now it's business as usual\n",
    "## 好了，这样就大功告成了，非常简单是不是~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f64098",
   "metadata": {},
   "source": [
    "# Something must note here!!!\n",
    "\n",
    "<br>\n",
    "\n",
    "在上面的示例代码中我们给出了如何使用 facebook 开发的库 “opacus” 来对寻常的深度学习模型的训练添加差分隐私。\n",
    "\n",
    "示例看起来非常简单，但是有几个值得注意的地方，首先是这个 Privacy_engine 中的设置，\n",
    "你可能会好奇这个 noise_multiplier, max_grad_norm 等都是什么意思~\n",
    "\n",
    "如果你真的一点都不理解的话，还是建议你从头看一遍这份笔记[Notes](./references/DP_notes.pdf). \n",
    "\n",
    "之后你可能会从这份 [F&Q](https://opacus.ai/docs/faq) 中获取补充内容，如果一切顺利的话，你应该可以大致了解这个类中的参数的具体含义了~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a611760",
   "metadata": {},
   "source": [
    "## How to build a generative model under differential privacy?\n",
    "\n",
    "在接下来的实验中请先确保你已经成功安装了pytorch和opacus！我们现在开始从头搭建一个DP框架下的生成模型~~~\n",
    "\n",
    "<br>\n",
    "\n",
    "考虑最简单的生成模型-DCGAN, 其生成器结构如下：\n",
    "\n",
    "<br>\n",
    "\n",
    "![avatar](./images/dcgan_generator.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "接下来，我们使用DP-SGD来训练这个一个DCGAN，看看是什么结果~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Runs DCGAN training with differential privacy.\n",
    "\n",
    "简单来说，因为我们使用DP-SGD的话会对梯度加噪声，很自然的，我们可以预期我们的生成结果不会很好。\n",
    "一般来说，小的模型会在DP框架下取得更好的效果（这里潜在的逻辑是： 越小的模型我们在反向转播是对梯度添加的噪声也越小，故而对模型性能的影响ye'bu's）。\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Runs DCGAN training with differential privacy.\n",
    "code from https://github.com/pytorch/opacus/blob/main/examples/dcgan.py\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from opacus import PrivacyEngine\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\"--data-root\", required=True, help=\"path to dataset\")\n",
    "parser.add_argument(\n",
    "    \"--workers\", type=int, help=\"number of data loading workers\", default=2\n",
    ")\n",
    "parser.add_argument(\"--batch-size\", type=int, default=64, help=\"input batch size\")\n",
    "parser.add_argument(\n",
    "    \"--imageSize\",\n",
    "    type=int,\n",
    "    default=64,\n",
    "    help=\"the height / width of the input image to network\",\n",
    ")\n",
    "parser.add_argument(\"--nz\", type=int, default=100, help=\"size of the latent z vector\")\n",
    "parser.add_argument(\"--ngf\", type=int, default=128)\n",
    "parser.add_argument(\"--ndf\", type=int, default=128)\n",
    "parser.add_argument(\n",
    "    \"--epochs\", type=int, default=25, help=\"number of epochs to train for\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--lr\", type=float, default=0.0002, help=\"learning rate, default=0.0002\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--beta1\", type=float, default=0.5, help=\"beta1 for adam. default=0.5\"\n",
    ")\n",
    "parser.add_argument(\"--ngpu\", type=int, default=1, help=\"number of GPUs to use\")\n",
    "parser.add_argument(\"--netG\", default=\"\", help=\"path to netG (to continue training)\")\n",
    "parser.add_argument(\"--netD\", default=\"\", help=\"path to netD (to continue training)\")\n",
    "parser.add_argument(\n",
    "    \"--outf\", default=\".\", help=\"folder to output images and model checkpoints\"\n",
    ")\n",
    "parser.add_argument(\"--manualSeed\", type=int, help=\"manual seed\")\n",
    "parser.add_argument(\n",
    "    \"--target-digit\",\n",
    "    type=int,\n",
    "    default=8,\n",
    "    help=\"the target digit(0~9) for MNIST training\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--device\",\n",
    "    type=str,\n",
    "    default=\"cuda\",\n",
    "    help=\"GPU ID for this process (default: 'cuda')\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--disable-dp\",\n",
    "    action=\"store_true\",\n",
    "    default=False,\n",
    "    help=\"Disable privacy training and just train with vanilla SGD\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--secure-rng\",\n",
    "    action=\"store_true\",\n",
    "    default=False,\n",
    "    help=\"Enable Secure RNG to have trustworthy privacy guarantees. Comes at a performance cost\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-r\",\n",
    "    \"--n-runs\",\n",
    "    type=int,\n",
    "    default=1,\n",
    "    metavar=\"R\",\n",
    "    help=\"number of runs to average on (default: 1)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--sigma\",\n",
    "    type=float,\n",
    "    default=1.0,\n",
    "    metavar=\"S\",\n",
    "    help=\"Noise multiplier (default 1.0)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-c\",\n",
    "    \"--max-per-sample-grad_norm\",\n",
    "    type=float,\n",
    "    default=1.0,\n",
    "    metavar=\"C\",\n",
    "    help=\"Clip per-sample gradients to this norm (default 1.0)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--delta\",\n",
    "    type=float,\n",
    "    default=1e-5,\n",
    "    metavar=\"D\",\n",
    "    help=\"Target delta (default: 1e-5)\",\n",
    ")\n",
    "\n",
    "opt = parser.parse_args()\n",
    "\n",
    "try:\n",
    "    os.makedirs(opt.outf)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "if opt.manualSeed is None:\n",
    "    opt.manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", opt.manualSeed)\n",
    "random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "\n",
    "try:\n",
    "    dataset = dset.MNIST(\n",
    "        root=opt.data_root,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(opt.imageSize),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    idx = dataset.targets == opt.target_digit\n",
    "    dataset.targets = dataset.targets[idx]\n",
    "    dataset.data = dataset.data[idx]\n",
    "    nc = 1\n",
    "except ValueError:\n",
    "    print(\"Cannot load dataset\")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=int(opt.workers),\n",
    "    batch_size=opt.batch_size,\n",
    ")\n",
    "\n",
    "device = torch.device(opt.device)\n",
    "ngpu = int(opt.ngpu)\n",
    "nz = int(opt.nz)\n",
    "ngf = int(opt.ngf)\n",
    "ndf = int(opt.ndf)\n",
    "\n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.GroupNorm(min(32, ndf * 8), ndf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.GroupNorm(min(32, ndf * 4), ndf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.GroupNorm(min(32, ndf * 2), ndf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.GroupNorm(min(32, ndf), ndf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output\n",
    "\n",
    "\n",
    "netG = Generator(ngpu)\n",
    "netG = netG.to(device)\n",
    "netG.apply(weights_init)\n",
    "if opt.netG != \"\":\n",
    "    netG.load_state_dict(torch.load(opt.netG))\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.GroupNorm(min(32, ndf * 2), ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.GroupNorm(min(32, ndf * 4), ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.GroupNorm(min(32, ndf * 8), ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "\n",
    "        return output.view(-1, 1).squeeze(1)\n",
    "\n",
    "\n",
    "netD = Discriminator(ngpu)\n",
    "netD = netD.to(device)\n",
    "netD.apply(weights_init)\n",
    "if opt.netD != \"\":\n",
    "    netD.load_state_dict(torch.load(opt.netD))\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "FIXED_NOISE = torch.randn(opt.batch_size, nz, 1, 1, device=device)\n",
    "REAL_LABEL = 1.0\n",
    "FAKE_LABEL = 0.0\n",
    "\n",
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "\n",
    "if not opt.disable_dp:\n",
    "    privacy_engine = PrivacyEngine(secure_mode=opt.secure_rng)\n",
    "\n",
    "    netD, optimizerD, dataloader = privacy_engine.make_private(\n",
    "        module=netD,\n",
    "        optimizer=optimizerD,\n",
    "        data_loader=dataloader,\n",
    "        noise_multiplier=opt.sigma,\n",
    "        max_grad_norm=opt.max_per_sample_grad_norm,\n",
    "    )\n",
    "\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "\n",
    "\n",
    "for epoch in range(opt.epochs):\n",
    "    data_bar = tqdm(dataloader)\n",
    "    for i, data in enumerate(data_bar, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "\n",
    "        optimizerD.zero_grad(set_to_none=True)\n",
    "\n",
    "        real_data = data[0].to(device)\n",
    "        batch_size = real_data.size(0)\n",
    "\n",
    "        # train with real\n",
    "        label_true = torch.full((batch_size,), REAL_LABEL, device=device)\n",
    "        output = netD(real_data)\n",
    "        errD_real = criterion(output, label_true)\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # train with fake\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        label_fake = torch.full((batch_size,), FAKE_LABEL, device=device)\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, label_fake)\n",
    "\n",
    "        # below, you actually have two backward passes happening under the hood\n",
    "        # which opacus happens to treat as a recursive network\n",
    "        # and therefore doesn't add extra noise for the fake samples\n",
    "        # noise for fake samples would be unnecesary to preserve privacy\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        errD.backward()\n",
    "        optimizerD.step()\n",
    "        optimizerD.zero_grad(set_to_none=True)\n",
    "\n",
    "        D_G_z1 = output.mean().item()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        optimizerG.zero_grad()\n",
    "\n",
    "        label_g = torch.full((batch_size,), REAL_LABEL, device=device)\n",
    "        output_g = netD(fake)\n",
    "        errG = criterion(output_g, label_g)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output_g.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if not opt.disable_dp:\n",
    "            epsilon = privacy_engine.accountant.get_epsilon(delta=opt.delta)\n",
    "            data_bar.set_description(\n",
    "                f\"epoch: {epoch}, Loss_D: {errD.item()} \"\n",
    "                f\"Loss_G: {errG.item()} D(x): {D_x} \"\n",
    "                f\"D(G(z)): {D_G_z1}/{D_G_z2}\"\n",
    "                \"(ε = %.2f, δ = %.2f)\" % (epsilon, opt.delta)\n",
    "            )\n",
    "        else:\n",
    "            data_bar.set_description(\n",
    "                f\"epoch: {epoch}, Loss_D: {errD.item()} \"\n",
    "                f\"Loss_G: {errG.item()} D(x): {D_x} \"\n",
    "                f\"D(G(z)): {D_G_z1}/{D_G_z2}\"\n",
    "            )\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            vutils.save_image(\n",
    "                real_data, \"%s/real_samples.png\" % opt.outf, normalize=True\n",
    "            )\n",
    "            fake = netG(FIXED_NOISE)\n",
    "            vutils.save_image(\n",
    "                fake.detach(),\n",
    "                \"%s/fake_samples_epoch_%03d.png\" % (opt.outf, epoch),\n",
    "                normalize=True,\n",
    "            )\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(netG.state_dict(), \"%s/netG_epoch_%d.pth\" % (opt.outf, epoch))\n",
    "    torch.save(netD.state_dict(), \"%s/netD_epoch_%d.pth\" % (opt.outf, epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f5878e",
   "metadata": {},
   "source": [
    "# How about your result?\n",
    "\n",
    "Note: 本实验可能需要一个至少（4G）的GPU才跑得起来，如果你遇到了GPU显存不够的问题，可以尝试如下一个解决思路\n",
    "- 调小 batch-size\n",
    "- 调小模型的大小（具体来说就是ndf和ngf）\n",
    "- 用cpu跑（如果你没有显卡的话~）\n",
    "\n",
    "<br>\n",
    "\n",
    "在这里，我给出的我的实验结果\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"./images/real_samples.png\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">真实的图片</div>\n",
    "</center>\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"./images/fake_samples_epoch_024.png\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">生成的图片</div>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "显然，我们可以发现对梯度加噪声这一步对模型的结果有很大的影响，具体来说\n",
    "- 从生成的结果来看，图片非常的模糊\n",
    "- 从多样性来看，模型陷入了 model collapse, 生成的图片的非常单一.\n",
    "\n",
    "自然的，我们可以考虑一个对一个更强的GAN来加DP，并希望这种方式能够取得更好的效果，或者其他方式，例如：\n",
    "\n",
    "<br>\n",
    "\n",
    "- 比如,考虑[wasserstein GAN](https://arxiv.org/abs/1704.00028)，这是GAN的一个突破，他解决了模型不易训练的问题，自然的，有人就已经做了这个工作[DP+WGAN](https://arxiv.org/pdf/1802.06739.pdf)\n",
    "\n",
    "<br>\n",
    "\n",
    "- 或者引入先验知识的CGAN, [DP+CGAN](https://arxiv.org/abs/2001.09700)\n",
    "\n",
    "<br>\n",
    "\n",
    "- 又或者，我们不考虑使用DPSGD，我们针对GAN的这种特定结构，对训练过程中的一部分加噪声，这就有了2020年CVPR的一篇文章[GS-WAGN](https://arxiv.org/pdf/2006.08265.pdf)\n",
    "\n",
    "<br>\n",
    "\n",
    "- 又或者，不管是DP-SGD还是GS-WGAN，他们都是基于训练过程的DP方式（对训练过程中的梯度加扰动），那么既然GAN在训练过程中其实是不断地衡量真实数据和生成数据之间的部分，那么，对于目标函数做扰动是不是可行的？这也就有了21年ICML的一篇文章 [DP-SWD](https://arxiv.org/pdf/2107.01848.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d15f02",
   "metadata": {},
   "source": [
    "#  GS-WGAN: A Gradient-Sanitized Approach for Learning Differentially Private Generators (NeurIPS 2020).\n",
    "\n",
    "<br>\n",
    "\n",
    "在之前的实验中，我们看到直接使用DP-SGD来训练DCGAN效果可以说是比较差的，这自然就使得研究人员去探究怎么去给生成模型加DP(或者说噪声)能够既保持一定的模型实用性，又能有比较好的DP保证。现在我们简单的讲一讲2020年NeurIPS的一篇文章[GS-WAGN](https://arxiv.org/pdf/2006.08265.pdf)。\n",
    "\n",
    "<br>\n",
    "\n",
    "首先，我们先来分析一下 DP-SGD 在干什么\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"./images/dp_sgd.png\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">DP_SGD</div>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "首先是正常的反向传播，得到各个网络层参数的梯度，然后为了确保差分隐私，我们需要为梯度添加噪声，这由两步组成\n",
    "- 梯度裁剪 $ clip(g^{(t)},C) $ ，这个C是一个人为给定的超参数，意思是我们的梯度最大不能超过这个阈值，这一步的目的是为了控制敏感度，可以这样直观理解，如果有某个部分的梯度特别重要，那我们会认为这一部分就容易受到攻击。\n",
    "\n",
    "- 添加噪声 $ +N(0, \\delta^2C^2I) $, 这一步就是正常的加噪步骤了。\n",
    "- 最后由被扰动的梯度代替原来的梯度进行反向传播。\n",
    "\n",
    "好，那DP_SGD的问题是什么呢？\n",
    "\n",
    "- 梯度裁剪这一步损失了太多的信息，自然导致了实用性的下降\n",
    "- 在实际的过程中，寻求一个合理的C（技能保证模型的性能，又能确保隐私）其实也并不容易。\n",
    "\n",
    "那怎么解决这个缺点呢， 作者通过针对GAN的结构选择性的添加噪声并结合 Wasserstein GAN 的想法对梯度加一个正则来控制这个敏感度。\n",
    "\n",
    "<br>\n",
    "\n",
    "首先是选择性的添加噪声机制\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"./images/GS_WGAN.png\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">GS-WGAN</div>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "上图显示了GS-WGAN的示意图，左图是正常的GAN的流程，右图是GS-WGAN的流程。\n",
    "\n",
    "<br>\n",
    "\n",
    "我们可以看到，正常的GAN的流程是什么？ 我们从高斯白噪声出发，经过生成器生成一个一张（或者一个batch）的假样本，然后我们将生成的样本和真实样本（也就是我们需要保护的数据）送入判别器，然后得到相应的loss, 然后梯度回传，更新判别器和生成器。\n",
    "\n",
    "<br>\n",
    "\n",
    "注意到，在上面我们使用DP-SGD训练DCGAN的时候，我们实际上是对判别器的梯度加了噪声，然后根据后处理机制，只要 $ \\Delta D(x) $ 是DP的，那么我生成器的梯度 $ g_G $ 也自然是DP的，这种方式实际上是对整个GAN都加了噪声。\n",
    "\n",
    "<br>\n",
    "\n",
    "然而，由于DP框架下生成模型的只需要我们 release 这个生成器 (generator)， 也就是说实际上我们并不需要对这整个模型加噪声，我们只要将这个DP机制加在生成器上，也就是说，我们的判别器还是正常的训练，只不过扰动的梯度代替生成器的梯度来训练我们的generator,如下：\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"./images/GS_WGAN_2.png\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">选择性的添加噪声</div>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "至于在损失函数中添加一个正则项来控制梯度不会太大（或者说控制敏感度）这一技巧也在论文中的[第4章节](https://arxiv.org/pdf/2006.08265.pdf), 这里我们就不展开讲了，有兴趣的同学可以自行阅读。\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"./images/GS_WGAN3.png\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">GS-WGAN的结果</div>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "我们可以看到，这个结果还是比较好的（至少在MINIST数据集上），这篇文章的代码可以在[这里](https://github.com/DingfanChen/GS-WGAN)找到，考虑到同学们可能并没有一个至少22G的显卡，这个模型可能大家跑不起来，因此，在这里，有条件的同学可以试一试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cc1265",
   "metadata": {},
   "source": [
    "# What should you do？\n",
    "\n",
    "到这里，我们的主体内容已经基本结束了，我们总结一下，到目前为止，我们基本为大家讲述了差分隐私目前在生成模型领域的一些进展。\n",
    "\n",
    "- 从最自然的想法——就是使用一个保证差分隐私的算法去训练一个生成模型（我们展示了如何使用DPSGD算法去训练DCGAN模型的例子）\n",
    "\n",
    "- 到发现直接用 DPSGD 算法去做不太好之后，研究人员选择了一些改进策略，比如选择性的添加噪声(这就有了GS-WGAN)\n",
    "\n",
    "- 又或者基于梯度扰动的算法可能不是很好，那我就直接做一个DP的目标函数(这就是[DP-SWD](https://arxiv.org/pdf/2107.01848.pdf)得想法）, 等等，这里不一一列举。\n",
    "\n",
    "<br>\n",
    "\n",
    "在上面我们简要介绍了GS-WGAN的核心想法，目的是希望大家能通过这个例子来理解当下的研究者是如何对这个问题进行改进的，这也是我们希望大家去探索的~\n",
    "\n",
    "具体来说，**我们希望大家能够做这些事情**: \n",
    "\n",
    "- 给出一个你天马行空的想法，可以参照下面的一些思路。\n",
    "- 如果可以的话，尽量给出你的实验结果。\n",
    "- 一份报告（或者说就是一个小论文），他并不一定要多么的严谨，但是核心内容应当是：你的想法是什么，依据是什么？\n",
    "\n",
    "实际上，我们并不要求大家一定要将这个作业的有多么的完备，换句话说，（可以没有严格的隐私分析，没有完备的实验，也没有太多仔细的分析，当然有是最好），那我们希望大家做什么？ 就是尽可能地给一个你的思路，然后用一些基本的实验或者理论来做支撑，如果条件允许的话，尽可能地给出你的实验，越详细越好。我们将根据大家的报告内容来给大家的这次作业打分，祝大家旅途愉快~\n",
    "\n",
    "<br>\n",
    "\n",
    "**一些可能的思路（2023.06）**：\n",
    "\n",
    "***探索不同的生成模型？*** \n",
    "\n",
    "我们前面看到使用DPSGD算法去训练DCGAN的效果是非常差的，那么有的人就想到了更好的生成模型[WassesteinGAN](https://arxiv.org/pdf/1802.06739.pdf).\n",
    "\n",
    "当然，既然是生成模型，我们自然可以不局限于GAN, [DP+VAE](https://arxiv.org/abs/1812.02274)的方式也是可行的.\n",
    "\n",
    "或者，和最近大火的扩散模型结合起来？比如[DP+DDPM](https://nv-tlabs.github.io/DPDM/)或者[这个](https://arxiv.org/abs/2302.13861)\n",
    "（PS：之前看的时候还没有太多人做，好像现在已经卷起来了~）\n",
    "\n",
    "***不同的训练方式？***\n",
    "\n",
    "比如换一个DP框架，比如下面是一些基于PATE框架的文章\n",
    "- [PATE-GAN](https://openreview.net/forum?id=S1zk9iRqF7)，\n",
    "- [Data-Lens](https://arxiv.org/pdf/2103.11109.pdf)\n",
    "- [G-PATE](https://arxiv.org/abs/1906.09338)\n",
    "\n",
    "***不同的数据场景？***\n",
    "\n",
    "在之前的介绍中研究着们其实专注于结构化的数据生成，我们是不是可以考虑非结构化的图数据生成策略（当然可以，其实已经有一些人在尝试了~）\n",
    "\n",
    "一个核心的问题是，当我们尝试非结构化数据的时候，我们需要考虑那些问题，这里我们给出一些方向，比如\n",
    "\n",
    "   - sampling定理在非结构化数据上怎么做? 简单来说就是给一张图，我们怎么去采样子图？可以参考的方向有[Random Walk Sampling](https://arxiv.org/abs/2301.00738)，有没有别的想法？\n",
    "   - Graph Condendation. 基于目前数据集压缩的一些工作，在结构化数据上已经见到了相关的[DP做法](https://arxiv.org/abs/2211.04446),那其实图数据集的压缩也是有的，比如[Graph Condensation for Graph Neural Networks](https://arxiv.org/abs/2110.07580)\n",
    "\n",
    "***又或者对现有的DP-SGD算法做改进？*** \n",
    "\n",
    "既然差分隐私在大模型上有维数灾难（用人话讲就是，大模型参数更多，自然的我要加的噪声也更多，那如果考虑梯度扰动的方法，我能不能把梯度先往低维空间投影，然后在加噪声，最后用这个低维的梯度在更新网络参数？），这方面地工作可以参考\n",
    "- [对网络每一层的参数做低秩的矩阵分解](https://arxiv.org/pdf/2106.09352.pdf), \n",
    "- 又或者[梯度的低维空间投影](https://openreview.net/forum?id=7dpmlkBuJFC).\n",
    "- more...\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a816c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl)",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
